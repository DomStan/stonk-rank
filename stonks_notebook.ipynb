{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance\n",
    "# !pip install pmdarima\n",
    "# !pip install hyperopt\n",
    "# !pip install xgboost\n",
    "# !pip install numpy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "import typing\n",
    "from typing import Dict\n",
    "from typing import Any\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import utils\n",
    "import pipelines\n",
    "import processing\n",
    "import evaluate\n",
    "import predict\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download stock daily prices & indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gets all ticker names (no argument given)\n",
    "market_cap_min_mm = 100\n",
    "market_cap_max_mm = 1000\n",
    "\n",
    "ticker_list = utils.get_ticker_names(\n",
    "    market_cap_min_mm=market_cap_min_mm,\n",
    "    market_cap_max_mm=market_cap_max_mm,\n",
    "    remove_industries = ['diversified_financials', 'pharmaceuticals_biotechnology_and_life_sciences'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific date - 3rd of March 2022 (Y, M, D)\n",
    "# date_to = datetime(2021, 1, 18)\n",
    "### Date of today\n",
    "date_to = datetime.today()\n",
    "### How many years' of data to download (going backwards from date_end). Year can be a floating point number\n",
    "period_years = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1210 of 1210 completed\n",
      "\n",
      "7 Failed downloads:\n",
      "- XENT: No data found, symbol may be delisted\n",
      "- GNOG: No data found, symbol may be delisted\n",
      "- LAWS: No data found, symbol may be delisted\n",
      "- BKSY.WS: No data found, symbol may be delisted\n",
      "- SHPW.WS: No data found, symbol may be delisted\n",
      "- IIN: No data found, symbol may be delisted\n",
      "- PROG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df, df_clean = utils.download_stonk_prices(\n",
    "    ticker_list.index, period_years=period_years, date_to=date_to\n",
    ")\n",
    "vix, vix_clean = utils.download_stonk_prices(\n",
    "    [\"^VIX\"], period_years=period_years, date_to=date_to, fname_prefix=\"vix\"\n",
    ")\n",
    "sp500, sp500_clean = utils.download_stonk_prices(\n",
    "    [\"^GSPC\"], period_years=period_years, date_to=date_to, fname_prefix=\"sp500\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries = [\n",
    "    # # 'health_care_equipment_and_services',\n",
    "    # 'software_and_services',\n",
    "    # 'retailing',\n",
    "    # 'telecommunication_services',\n",
    "    # \"capital_goods\",\n",
    "    'energy',\n",
    "    # # 'pharmaceuticals_biotechnology_and_life_sciences',\n",
    "    # 'consumer_staples',\n",
    "    # 'banks',\n",
    "    # 'diversified_financials',\n",
    "    # 'metals_and_mining',\n",
    "    # 'technology_hardware_and_equipment',\n",
    "    # 'utilities',\n",
    "    # 'chemicals',\n",
    "    # 'automobiles_and_components',\n",
    "    # 'semiconductors_and_semiconductor_equipment',\n",
    "    # 'media_and_entertainment',\n",
    "    # 'real_estate',\n",
    "    # 'consumer_services',\n",
    "    # 'consumer_durables_and_apparel',\n",
    "    # 'insurance',\n",
    "    # 'transportation',\n",
    "    # 'commercial_and_professional_services',\n",
    "    # 'paper_and_forest_products',\n",
    "    # 'containers_and_packaging',\n",
    "    # 'construction_materials'\n",
    "]\n",
    "\n",
    "l_reg = 3\n",
    "l_roll = 2\n",
    "dt = 10\n",
    "\n",
    "market_cap_max_string = \"max\" if market_cap_max_mm is None else str(market_cap_max_mm)\n",
    "pipeline_dir = \"pipeline_run_\" + str(market_cap_min_mm) + \"_to_\" + market_cap_max_string + \"_cap\"\n",
    "output_dir = os.path.join(\"data\", pipeline_dir)\n",
    "\n",
    "stonk_model = predict.XGBStonkModel()\n",
    "vix = utils.get_stonk_data(fname_prefix=\"vix\", disable_filter=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "i = 1\n",
    "total_industries = len(industries)\n",
    "for industry in industries:\n",
    "    stonks = utils.get_stonk_data(filter_industries=[industry])\n",
    "    X, Y = processing.combine_stonk_pairs(stonks)\n",
    "\n",
    "    print(\"Industry ({0}/{1}): {2}\".format(i, total_industries, industry))\n",
    "\n",
    "    print(\"Processing residuals...\")\n",
    "    residuals, betas, _, dates_index = utils.measure_time(\n",
    "        partial(\n",
    "            processing.get_rolling_residuals,\n",
    "            X=X,\n",
    "            Y=Y,\n",
    "            l_reg=l_reg,\n",
    "            l_roll=l_roll,\n",
    "            dt=dt,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    std_residuals, means, stds = processing.get_standardized_residuals(\n",
    "        residuals\n",
    "    )\n",
    "\n",
    "    trades_before = len(std_residuals)\n",
    "    std_residuals = std_residuals[std_residuals.iloc[:, -1].abs() >= 2.5]\n",
    "    trades_after = len(std_residuals)\n",
    "    print(\n",
    "        \"{0} trades selected out of {1} by residual values\".format(\n",
    "            trades_after, trades_before\n",
    "        )\n",
    "    )\n",
    "    if trades_after == 0:\n",
    "        continue\n",
    "        \n",
    "    residuals = residuals.loc[std_residuals.index]\n",
    "    betas = betas.loc[std_residuals.index]\n",
    "    dates_index = dates_index.loc[std_residuals.index]\n",
    "\n",
    "    print(\"Processing ADFs...\")\n",
    "    adfs, adfs_raw = utils.measure_time(\n",
    "        partial(\n",
    "            processing.get_aggregate_adfs,\n",
    "            residuals,\n",
    "            betas=betas,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    selected_by_adf = (adfs >= 0.5).values\n",
    "    adfs = adfs[selected_by_adf]\n",
    "\n",
    "    trades_before = len(std_residuals)\n",
    "    std_residuals = std_residuals[selected_by_adf]\n",
    "    trades_after = len(std_residuals)\n",
    "    print(\n",
    "        \"{0} trades selected out of {1} by ADF pass rates\".format(\n",
    "            trades_after, trades_before\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if len(std_residuals) == 0:\n",
    "        continue\n",
    "\n",
    "    betas = betas.loc[adfs.index]\n",
    "    \n",
    "    residuals = residuals.loc[adfs.index]\n",
    "    adfs_raw = adfs_raw.loc[adfs.index]\n",
    "    \n",
    "    dates_index = dates_index.loc[std_residuals.index]\n",
    "    \n",
    "    means = means.loc[std_residuals.index]\n",
    "    stds = stds.loc[std_residuals.index]\n",
    "\n",
    "    residuals_max_mean = processing.get_mean_residual_magnitude(\n",
    "        std_residuals.to_numpy(), dt=21\n",
    "    )\n",
    "    print(\n",
    "        \"Mean max residual value for {0} after filtering is {1}\".format(\n",
    "            industry, residuals_max_mean\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"Processing beta stability tests...\")\n",
    "    beta_stability_rsquared_vals = utils.measure_time(\n",
    "        partial(\n",
    "            processing.calculate_beta_stability_rsquared,\n",
    "            prices_X=X, prices_Y=Y, betas=betas, dates_index=dates_index\n",
    "        )\n",
    "    )\n",
    "    assert np.all(beta_stability_rsquared_vals.index == std_residuals.index)\n",
    "    \n",
    "    print(\"Processing ARIMA forecasts...\")\n",
    "    arima_forecasts = utils.measure_time(\n",
    "        partial(\n",
    "            processing.calculate_arima_forecast,\n",
    "            std_residuals=std_residuals,\n",
    "            forecast_months=3,\n",
    "            eval_models=5,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"Preparing data for model...\")\n",
    "    dataset = utils.build_dataset_from_live_data_by_industry(\n",
    "        std_residuals=std_residuals,\n",
    "        adfs=adfs,\n",
    "        subindustry=industry,\n",
    "        mean_max_residual=residuals_max_mean,\n",
    "        vix_index=vix.loc[stonks.columns[-1]],\n",
    "        betas_stability_rsquared=beta_stability_rsquared_vals,\n",
    "        arima_forecasts=arima_forecasts\n",
    "    )\n",
    "\n",
    "    print(\"Running model...\")\n",
    "    predictions, df_processed = stonk_model.predict(dataset)\n",
    "    datasets.append((dataset, df_processed))\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.index = adfs.index\n",
    "\n",
    "    residuals.insert(0, \"dates\", dates_index.values)\n",
    "    betas.insert(0, \"dates\", dates_index.values)\n",
    "    \n",
    "    print(\"Writing results to CSV...\")\n",
    "    # Very big industry, exceeds Git file size limit\n",
    "    if industry == \"diversified_financials\":\n",
    "        half = len(residuals) // 2\n",
    "        residuals_fst = residuals.iloc[:half]\n",
    "        residuals_snd = residuals.iloc[half:]\n",
    "        residuals_fst.to_csv(\n",
    "            os.path.join(output_dir, industry + \"_one_residuals.csv\"),\n",
    "            header=False,\n",
    "            index=True,\n",
    "        )\n",
    "        residuals_snd.to_csv(\n",
    "            os.path.join(output_dir, industry + \"_two_residuals.csv\"),\n",
    "            header=False,\n",
    "            index=True,\n",
    "        )\n",
    "        del residuals_fst\n",
    "        del residuals_snd\n",
    "    else:\n",
    "        residuals.to_csv(\n",
    "            os.path.join(output_dir, industry + \"_residuals.csv\"),\n",
    "            header=False,\n",
    "            index=True,\n",
    "        )\n",
    "    betas.to_csv(\n",
    "        os.path.join(output_dir, industry + \"_betas.csv\"), header=False, index=True\n",
    "    )\n",
    "    adfs_raw.to_csv(\n",
    "        os.path.join(output_dir, industry + \"_adfs_raw.csv\"), header=False, index=True\n",
    "    )\n",
    "    predictions.to_csv(\n",
    "        os.path.join(output_dir, industry + \"_predictions.csv\"),\n",
    "        header=False,\n",
    "        index=True,\n",
    "    )\n",
    "    arima_forecasts.to_csv(\n",
    "        os.path.join(output_dir, industry + \"_arima.csv\"),\n",
    "        header=False,\n",
    "        index=True,\n",
    "    )\n",
    "    beta_stability_rsquared_vals.to_csv(\n",
    "        os.path.join(output_dir, industry + \"_rsquared.csv\"),\n",
    "        header=False,\n",
    "        index=True,\n",
    "    )\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"*** All done ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stonks = utils.get_stonk_data(disable_filter=True)\n",
    "# stonks = stonks.loc[:, :\"2020-05-08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data windows: 72\n"
     ]
    }
   ],
   "source": [
    "pipelines.data_collection_rolling_pipeline(\n",
    "    stonks,\n",
    "    l_reg=3,\n",
    "    l_roll=2,\n",
    "    dt=10,\n",
    "    market_cap_min_mm=100,\n",
    "    market_cap_max_mm=1000,\n",
    "    last_residual_cutoff=2,\n",
    "    mean_max_residual_dt=21,\n",
    "    adf_pval_cutoff=0.1,\n",
    "    adf_pass_rate_filter=0.5,\n",
    "    arima_forecast_months=3,\n",
    "    arima_eval_models=5,\n",
    "    trade_length_months=3,\n",
    "    trading_interval_weeks=2,\n",
    "    remove_industries = ['diversified_financials', 'pharmaceuticals_biotechnology_and_life_sciences', 'containers_and_packaging'],\n",
    "    first_n_windows=72,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.ingest_trade_pipeline_outputs()\n",
    "\n",
    "vix = utils.get_stonk_data(fname_prefix=\"vix\", disable_filter=True).iloc[0]\n",
    "sp500 = utils.get_stonk_data(fname_prefix=\"sp500\", disable_filter=True).iloc[0]\n",
    "\n",
    "sp500_chg = pd.Series((sp500.iloc[63:].values / sp500.iloc[:-63].values) - 1)\n",
    "sp500_chg.index = sp500.iloc[63:].index\n",
    "\n",
    "dataset[\"vix\"] = dataset[\"trade_date\"].apply(lambda x: vix.loc[x])\n",
    "dataset[\"sp500\"] = dataset[\"trade_date\"].apply(lambda x: sp500_chg.loc[x])\n",
    "dataset.to_csv(\"data/dataset_smallcap.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, STATUS_FAIL, Trials, fmin, hp, tpe, atpe, rand\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_production_xgb(\n",
    "    df: pd.DataFrame, params: Dict[str, Any], noise_level: float = 0\n",
    ") -> Tuple[xgb.XGBClassifier, sklearn.base.TransformerMixin]:\n",
    "    X_train, scalers = preprocessing.transform_features(df, noise_level=noise_level)\n",
    "    y_train = df[\"label\"]\n",
    "\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_train, y_train)])\n",
    "    clf.save_model(os.path.join(\"data\", \"xgb_classifier.json\"))\n",
    "\n",
    "    with open(os.path.join(\"data\", \"scalers.json\"), \"wb\") as fp:\n",
    "        pickle.dump(scalers, fp)\n",
    "\n",
    "    return clf, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "df = df[df.beta > 0]\n",
    "df = df[df.last_residual.abs() >= 2.5]\n",
    "df = preprocessing.assign_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92655\n",
      "0    79266\n",
      "1    13389\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_dates = 18\n",
    "selected_dates = np.sort(df[\"trade_date\"].unique())[drop_dates:]\n",
    "df_prod = df[df.trade_date.isin(selected_dates)].sample(frac=1)\n",
    "print(len(df_prod))\n",
    "print(df_prod[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_prod, scalers_prod = train_production_xgb(df_prod, params, noise_level=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98187\n",
      "3605\n",
      "0    79429\n",
      "1    18758\n",
      "Name: label, dtype: int64\n",
      "0    2792\n",
      "1     813\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "splits = preprocessing.split_data(df, 2, 6, 10, random_state=432233293)\n",
    "print(len(splits[\"train\"]))\n",
    "print(len(splits[\"validation\"]))\n",
    "print(splits[\"train\"][\"label\"].value_counts())\n",
    "print(splits[\"validation\"][\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.005\n",
    "\n",
    "X_train, scalers = preprocessing.transform_features(\n",
    "    splits[\"train\"], noise_level=noise_level\n",
    ")\n",
    "X_valid, _ = preprocessing.transform_features(\n",
    "    splits[\"validation\"], scalers=scalers, noise_level=0\n",
    ")\n",
    "\n",
    "y_train = splits[\"train\"][\"label\"]\n",
    "y_valid = splits[\"validation\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = {\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0, 5),\n",
    "    \"scale_pos_weight\": hp.uniform(\"scale_pos_weight\", 3, 7),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 3, 8, 1),\n",
    "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 8, 1),\n",
    "    \"max_delta_step\": hp.quniform(\"max_delta_step\", 1, 4, 1),\n",
    "    \"n_estimators\": hp.quniform(\"n_estimators\", 25, 80, 1),\n",
    "    # \"n_estimators\": hp.choice(\"n_estimators\", np.array([50, 75, 100, 150, 200])),\n",
    "    # \"subsample\": hp.uniform(\"subsample\", 0.9, 1),\n",
    "    # \"colsample_bylevel\" : hp.uniform(\"colsample_bylevel\", 0.5, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def optimization_objective(space):\n",
    "    clf = xgb.XGBClassifier(\n",
    "        gamma=space[\"gamma\"],\n",
    "        scale_pos_weight=space[\"scale_pos_weight\"],\n",
    "        #\n",
    "        max_depth=int(space[\"max_depth\"]),\n",
    "        min_child_weight=int(space[\"min_child_weight\"]),\n",
    "        max_delta_step=int(space[\"max_delta_step\"]),\n",
    "        #\n",
    "        # colsample_bylevel = space['colsample_bylevel'],\n",
    "        colsample_bylevel=1,\n",
    "        n_estimators=int(space[\"n_estimators\"]),\n",
    "        learning_rate=0.1,\n",
    "        # subsample = space['subsample'],\n",
    "        subsample=0.99,\n",
    "        #\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=True,\n",
    "        max_cat_to_onehot=1,\n",
    "        random_state=np.random.randint(9999999),\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    y_score = clf.predict_proba(X_valid)[:, 1]\n",
    "    y_preds = y_score > 0.5\n",
    "\n",
    "    f1 = f1_score(y_valid, y_preds, zero_division=0)\n",
    "    precision = precision_score(y_valid, y_preds, zero_division=0)\n",
    "    ap = evaluate.average_precision_from_cutoff(y_valid, y_score, 0)\n",
    "    roc = roc_auc_score(y_valid, y_score)\n",
    "\n",
    "    pos_preds = int(y_preds.sum())\n",
    "    pos_labels = int(y_valid.sum())\n",
    "\n",
    "    ap = ap if pos_preds >= pos_labels else 0\n",
    "\n",
    "    if f1 == 0 or precision == 0:\n",
    "        return {\n",
    "            \"loss\": 100,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": f1,\n",
    "            \"ap\": ap,\n",
    "            \"auc\": roc,\n",
    "            \"pos_preds\": pos_preds,\n",
    "            \"status\": STATUS_FAIL,\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"loss\": -ap,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": f1,\n",
    "            \"ap\": ap,\n",
    "            \"auc\": roc,\n",
    "            \"pos_preds\": pos_preds,\n",
    "            \"status\": STATUS_OK,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:16<00:00,  2.94trial/s, best loss: -0.3041476716238842]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(\n",
    "    fn=optimization_objective,\n",
    "    space=hyperparameter_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=400,\n",
    "    trials=trials,\n",
    ")\n",
    "\n",
    "trial_vals = trials.vals\n",
    "trial_vals[\"f1_score\"] = list(map(lambda x: x[\"f1_score\"], trials.results))\n",
    "trial_vals[\"precision\"] = list(map(lambda x: x[\"precision\"], trials.results))\n",
    "trial_vals[\"ap\"] = list(map(lambda x: x[\"ap\"], trials.results))\n",
    "trial_vals[\"auc\"] = list(map(lambda x: x[\"auc\"], trials.results))\n",
    "trial_vals[\"pos_preds\"] = list(map(lambda x: x[\"pos_preds\"], trials.results))\n",
    "\n",
    "df_trials = pd.DataFrame.from_dict(trial_vals)\n",
    "df_trials.to_csv(\"data/experiments/data_window_size_24#1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # reg def 0\n",
    "    \"gamma\": 4.159451,\n",
    "    # L2 def 1\n",
    "    # \"reg_lambda\" : 1,\n",
    "    # \"reg_alpha\" : 0,\n",
    "    # Class imbalance def 1\n",
    "    \"scale_pos_weight\": 5.631922,\n",
    "    # Integers:\n",
    "    \"max_depth\": 6,\n",
    "    # Reg def 1\n",
    "    \"min_child_weight\": 3,\n",
    "    # Class imbalance def 0\n",
    "    \"max_delta_step\": 2,\n",
    "    # Choice:\n",
    "    \"colsample_bylevel\": 1,\n",
    "    \"n_estimators\": 55,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 1,\n",
    "    # Fixed:\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"enable_categorical\": True,\n",
    "    \"max_cat_to_onehot\": 1,\n",
    "    \"eval_metric\": [\"logloss\"],\n",
    "    \"random_state\": np.random.randint(999929),\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid), (X_train, y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**Validation**\")\n",
    "y_score = clf.predict_proba(X_valid)[:, 1]\n",
    "thres = 0.5\n",
    "y_preds = y_score > thres\n",
    "\n",
    "evaluate.performance_summary(y_score, y_preds, y_valid, auc_cutoff=0.4)\n",
    "\n",
    "df_results_valid = evaluate.returns_on_predictions(splits[\"validation\"], y_preds)\n",
    "\n",
    "evaluate.performance_on_slice(\n",
    "    splits[\"validation\"], y_score, y_preds, \"subindustry\", False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_valid[df_results_valid.result == \"FP\"].iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_valid[df_results_valid.subindustry == 'consumer_services'].iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adf_pass_rate 0.04439353\n",
      "last_residual 0.074401274\n",
      "residual_mean_max 0.13986948\n",
      "vix 0.34344476\n",
      "betas_rsquared 0.051621858\n",
      "arima_forecast 0.08900969\n",
      "industry 0.2032127\n",
      "residual_inter 0.054046713\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(clf.feature_names_in_, clf.feature_importances_):\n",
    "    print(name, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>ap</th>\n",
       "      <th>auc</th>\n",
       "      <th>pos_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>4.402027</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.036233</td>\n",
       "      <td>0.301226</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.307824</td>\n",
       "      <td>0.612917</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2.571218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.152819</td>\n",
       "      <td>0.303274</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.306634</td>\n",
       "      <td>0.605328</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2.905877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.193479</td>\n",
       "      <td>0.307246</td>\n",
       "      <td>0.290570</td>\n",
       "      <td>0.306370</td>\n",
       "      <td>0.606830</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2.268182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.801728</td>\n",
       "      <td>0.326882</td>\n",
       "      <td>0.290353</td>\n",
       "      <td>0.306365</td>\n",
       "      <td>0.608112</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.807177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.940918</td>\n",
       "      <td>0.303207</td>\n",
       "      <td>0.288248</td>\n",
       "      <td>0.306070</td>\n",
       "      <td>0.608726</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.619195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.634449</td>\n",
       "      <td>0.298363</td>\n",
       "      <td>0.294258</td>\n",
       "      <td>0.306050</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3.901148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.543907</td>\n",
       "      <td>0.298235</td>\n",
       "      <td>0.295181</td>\n",
       "      <td>0.305957</td>\n",
       "      <td>0.610852</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1.661592</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.682743</td>\n",
       "      <td>0.297770</td>\n",
       "      <td>0.291962</td>\n",
       "      <td>0.305486</td>\n",
       "      <td>0.611061</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.400583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.943170</td>\n",
       "      <td>0.301290</td>\n",
       "      <td>0.287794</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>0.609473</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3.433409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.977905</td>\n",
       "      <td>0.300236</td>\n",
       "      <td>0.288965</td>\n",
       "      <td>0.305130</td>\n",
       "      <td>0.610926</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma  max_delta_step  max_depth  min_child_weight  n_estimators  \\\n",
       "148  4.402027             2.0        3.0               4.0          46.0   \n",
       "390  2.571218             1.0        3.0               8.0          79.0   \n",
       "397  2.905877             1.0        3.0               7.0          77.0   \n",
       "192  2.268182             1.0        3.0               8.0          72.0   \n",
       "257  1.807177             1.0        3.0               8.0          63.0   \n",
       "120  0.619195             1.0        3.0               8.0          55.0   \n",
       "109  3.901148             1.0        3.0               8.0          51.0   \n",
       "287  1.661592             2.0        3.0               5.0          59.0   \n",
       "86   1.400583             1.0        3.0               7.0          62.0   \n",
       "135  3.433409             2.0        3.0               4.0          57.0   \n",
       "\n",
       "     scale_pos_weight  f1_score  precision        ap       auc  pos_preds  \n",
       "148          5.036233  0.301226   0.286667  0.307824  0.612917        900  \n",
       "390          5.152819  0.303274   0.284483  0.306634  0.605328        928  \n",
       "397          5.193479  0.307246   0.290570  0.306370  0.606830        912  \n",
       "192          5.801728  0.326882   0.290353  0.306365  0.608112       1047  \n",
       "257          4.940918  0.303207   0.288248  0.306070  0.608726        902  \n",
       "120          4.634449  0.298363   0.294258  0.306050  0.610108        836  \n",
       "109          4.543907  0.298235   0.295181  0.305957  0.610852        830  \n",
       "287          4.682743  0.297770   0.291962  0.305486  0.611061        846  \n",
       "86           4.943170  0.301290   0.287794  0.305466  0.609473        893  \n",
       "135          4.977905  0.300236   0.288965  0.305130  0.610926        879  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials = pd.read_csv(\"data/experiments/data_window_size_8#1.csv\")\n",
    "df_trials.sort_values(\"ap\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>ap</th>\n",
       "      <th>auc</th>\n",
       "      <th>pos_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3.906547</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.716516</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.277679</td>\n",
       "      <td>0.313899</td>\n",
       "      <td>0.600266</td>\n",
       "      <td>1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3.469554</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.027040</td>\n",
       "      <td>0.379252</td>\n",
       "      <td>0.289799</td>\n",
       "      <td>0.312570</td>\n",
       "      <td>0.607180</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>3.522302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.160963</td>\n",
       "      <td>0.380520</td>\n",
       "      <td>0.286335</td>\n",
       "      <td>0.308583</td>\n",
       "      <td>0.600154</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3.563187</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.246752</td>\n",
       "      <td>0.379491</td>\n",
       "      <td>0.282452</td>\n",
       "      <td>0.308114</td>\n",
       "      <td>0.598825</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.403024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.610162</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.287394</td>\n",
       "      <td>0.307838</td>\n",
       "      <td>0.607987</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3.270269</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.091447</td>\n",
       "      <td>0.376421</td>\n",
       "      <td>0.286172</td>\n",
       "      <td>0.307594</td>\n",
       "      <td>0.603345</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>3.907869</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.355520</td>\n",
       "      <td>0.373591</td>\n",
       "      <td>0.277678</td>\n",
       "      <td>0.307327</td>\n",
       "      <td>0.598120</td>\n",
       "      <td>1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.160591</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.456795</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.314477</td>\n",
       "      <td>0.307306</td>\n",
       "      <td>0.606309</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.560098</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.963571</td>\n",
       "      <td>0.368747</td>\n",
       "      <td>0.300933</td>\n",
       "      <td>0.307297</td>\n",
       "      <td>0.604676</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2.791044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.435629</td>\n",
       "      <td>0.381105</td>\n",
       "      <td>0.282493</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma  max_delta_step  max_depth  min_child_weight  n_estimators  \\\n",
       "134  3.906547             3.0        5.0               6.0          66.0   \n",
       "112  3.469554             2.0        5.0               3.0          52.0   \n",
       "314  3.522302             3.0        5.0               5.0          58.0   \n",
       "116  3.563187             4.0        5.0               3.0          51.0   \n",
       "177  1.403024             1.0        8.0               5.0          64.0   \n",
       "214  3.270269             4.0        5.0               4.0          67.0   \n",
       "221  3.907869             3.0        5.0               1.0          62.0   \n",
       "48   2.160591             2.0        5.0               3.0          41.0   \n",
       "38   1.560098             4.0        5.0               3.0          52.0   \n",
       "282  2.791044             4.0        5.0               3.0          74.0   \n",
       "\n",
       "     scale_pos_weight  f1_score  precision        ap       auc  pos_preds  \n",
       "134          6.716516  0.374900   0.277679  0.313899  0.600266       1689  \n",
       "112          6.027040  0.379252   0.289799  0.312570  0.607180       1539  \n",
       "314          6.160963  0.380520   0.286335  0.308583  0.600154       1610  \n",
       "116          6.246752  0.379491   0.282452  0.308114  0.598825       1664  \n",
       "177          6.610162  0.375427   0.287394  0.307838  0.607987       1531  \n",
       "214          6.091447  0.376421   0.286172  0.307594  0.603345       1562  \n",
       "221          6.355520  0.373591   0.277678  0.307327  0.598120       1671  \n",
       "48           4.456795  0.353448   0.314477  0.307306  0.606309       1043  \n",
       "38           4.963571  0.368747   0.300933  0.307297  0.604676       1286  \n",
       "282          6.435629  0.381105   0.282493  0.306633  0.603704       1685  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials = pd.read_csv(\"data/experiments/data_window_size_20#1.csv\")\n",
    "df_trials.sort_values(\"ap\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = pd.read_csv(\"data/data-window-size-2#6.csv\")\n",
    "df_trials.sort_values(\"ap\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
